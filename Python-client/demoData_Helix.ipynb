{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight: 400; font-size: 16px; font-style: normal\">1. Import Librairies</span>\n",
    "\n",
    "<span style=\"color:green;font-weight: 400; font-size: 16px; font-style: normal\">   Connect to API EndPoint</span>\n",
    "\n",
    "<span style=\"color:green;font-weight: 400; font-size: 16px; font-style: normal\">   Create the Workspace</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctm_python_client.core.workflow import *\n",
    "from ctm_python_client.core.comm import *\n",
    "from ctm_python_client.core.credential import *\n",
    "from aapi import *\n",
    "from ctm_python_client.ext.viz import get_graph\n",
    "import os\n",
    "BASE_PATH = os.path.abspath(\"\")\n",
    "with open(BASE_PATH + \"/secrets\", \"r\") as fp:\n",
    "    ctm_key = fp.readline().strip()\n",
    "\n",
    "URL='https://.controlm.com/automation-api'\n",
    "\n",
    "my_environment = Environment.create_saas(URL,\n",
    "                                         api_key=ctm_key)\n",
    "MyCTM = \"IN01\"\n",
    "workflow = Workflow(my_environment,\n",
    "                    WorkflowDefaults(controlm_server=MyCTM,\n",
    "                                     application='MPE',\n",
    "                                     sub_application='Module4')\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight: 400; font-size: 16px; font-style: normal\">2. Create the Folder and jobs</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Myfolder = \"mpe-data-pipeline\"\n",
    "MySITE = \"mpe_site1\"\n",
    "# Folder\n",
    "folder = Folder(Myfolder,\n",
    "                site_standard=MySITE,\n",
    "                description='Control-M Data Pipeline',\n",
    "                order_method=Folder.OrderMethod.Manual,\n",
    "                variables=[\n",
    "                     {'EXTRACT_CSV': '/tmp/snowflake_query.csv'},\n",
    "                     {'MYFILE': 'demo123.txt'}\n",
    "                     ])\n",
    "workflow.add(folder)\n",
    "\n",
    "\n",
    "#  Jobs\n",
    "myJobOS1 = JobCommand(\"OS-linux1\", \n",
    "               command='df -h', \n",
    "               run_as='bmc',\n",
    "               host='zzz-linux-agents'\n",
    "               )\n",
    "\n",
    "myJobOS2 = JobCommand(\"OS-linux2\", \n",
    "               command='sleep 5', \n",
    "               run_as='bmc',\n",
    "               host='zzz-linux-agents'\n",
    "               )\n",
    "\n",
    "myJobDB1 = JobDatabaseEmbeddedQuery(\"Postgres-data\", \n",
    "                             query='select title,release_year from film',\n",
    "                             connection_profile='MPE_PGSQL', \n",
    "                             host='zzz-eks-sandbox-1.bmci2t.com',\n",
    "                             output_execution_log='N', output_sql_output='Y', sql_output_format='CSV', run_as='MPE_PGSQL',\n",
    "                             output=Job.Output(\n",
    "                                 operation=Job.Output.Operation.Copy, destination='%%EXTRACT_CSV')\n",
    "                             )\n",
    "\n",
    "myJobAZ1 = JobFileTransfer(\"Transfer-to-Azure-Blob\",\n",
    "                    host='zzz-eks-sandbox-1.bmci2t.com',\n",
    "                    connection_profile_src='ZZZ_MFT_FS_1', \n",
    "                    connection_profile_dest='ZZZ_MFT_BLOB',\n",
    "                    azure_container_name_dest='incoming',\n",
    "                    number_of_retries='5', \n",
    "                    file_transfers=[\n",
    "                        FileTransfer(src='%%EXTRACT_CSV', dest='/',\n",
    "                                     transfer_type=FileTransfer.TransferType.Binary,\n",
    "                                     transfer_option=FileTransfer.TransferOption.SrcToDest),\n",
    "                   ]\n",
    "                )\n",
    "\n",
    "\n",
    "myJobADF = JobAzureDataFactory(\"Azure Data Factory-Job\",\n",
    "                   connection_profile='ZZZ_AZE_DAFA',\n",
    "                   resource_group_name='mpe-res1',\n",
    "                   data_factory_name='mpe-datafactory',\n",
    "                   host='zzz-eks-sandbox-1.bmci2t.com',\n",
    "                   pipeline_name='PipelineCRM',\n",
    "                   parameters='{}',\n",
    "                   status_polling_frequency='20'\n",
    "                   )\n",
    "\n",
    "\n",
    "\n",
    "myJobBlobS3 = JobFileTransfer(\"Azure-Blob-to-AWS-S3\",\n",
    "                    connection_profile_src='ZZZ_MFT_BLOB', \n",
    "                    connection_profile_dest='ZZZ_MFT_S3',\n",
    "                    azure_container_name_src='outgoing',\n",
    "                    s3_bucket_name_dest='zzz-file-upload-s3',\n",
    "                    number_of_retries='5', \n",
    "                    host='zzz-linux-agents',\n",
    "                    file_transfers=[\n",
    "                        FileTransfer(src='/snowflake_query.csv', dest='/',\n",
    "                                     transfer_type=FileTransfer.TransferType.Binary,\n",
    "                                     transfer_option=FileTransfer.TransferOption.SrcToDest),\n",
    "                    ]\n",
    "                    )\n",
    "\n",
    "myJobAWS = JobAWSLambda(\"AWS-lambda\",\n",
    "                   connection_profile='ZZZ_AWS',\n",
    "                   function_name='mpe-test1',\n",
    "                   version='$LATEST',\n",
    "                   host='zzz-linux-agents',\n",
    "                   payload='{\"Number1\": 974,\"Number2\": 78,\"filedemo\":\"%%MYFILE\"}',\n",
    "                   append_log=True\n",
    "                   )\n",
    "\n",
    "jobSLA = JobSLAManagement(Myfolder + \"-SLA\",\n",
    "                     service_name='mpe-demo-python',\n",
    "                     run_as='ctmagent',\n",
    "                     service_priority='1',\n",
    "                     host='zzz-linux-agents',\n",
    "                     job_runs_deviations_tolerance='1',\n",
    "                     complete_in=JobSLAManagement.CompleteIn(time='00:10'),\n",
    "                     average_run_time_tolerance=JobSLAManagement.AverageRunTimeTolerance(\n",
    "                         average_run_time='10',\n",
    "                         units=JobSLAManagement.AverageRunTimeTolerance.Units.Minutes\n",
    "                     )\n",
    "                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight: 400; font-size: 16px; font-style: normal\">3. Dependencies and check the Workflow: Build/Validate and Display</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The workflow is valid!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: root Pages: 1 -->\n",
       "<svg width=\"205pt\" height=\"531pt\"\n",
       " viewBox=\"0.00 0.00 205.00 531.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 527)\">\n",
       "<title>root</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-527 201,-527 201,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\"><title>cluster_0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"8,-8 8,-515 189,-515 189,-8 8,-8\"/>\n",
       "<text text-anchor=\"middle\" x=\"98.5\" y=\"-499.8\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mpe&#45;data&#45;pipeline</text>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/OS&#45;linux1 -->\n",
       "<g id=\"node1\" class=\"node\"><title>mpe&#45;data&#45;pipeline/OS&#45;linux1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"180.5,-484 107.5,-484 107.5,-448 180.5,-448 180.5,-484\"/>\n",
       "<text text-anchor=\"middle\" x=\"144\" y=\"-462.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">OS&#45;linux1</text>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/Postgres&#45;data -->\n",
       "<g id=\"node2\" class=\"node\"><title>mpe&#45;data&#45;pipeline/Postgres&#45;data</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"144.5,-412 51.5,-412 51.5,-376 144.5,-376 144.5,-412\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-390.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Postgres&#45;data</text>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/OS&#45;linux1&#45;&gt;mpe&#45;data&#45;pipeline/Postgres&#45;data -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/OS&#45;linux1&#45;&gt;mpe&#45;data&#45;pipeline/Postgres&#45;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M126.713,-447.697C120.591,-439.644 113.974,-429.894 108.527,-420.982\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"111.409,-418.976 103.345,-412.104 105.364,-422.505 111.409,-418.976\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/OS&#45;linux1&#45;&gt;mpe&#45;data&#45;pipeline/Postgres&#45;data -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/OS&#45;linux1&#45;&gt;mpe&#45;data&#45;pipeline/Postgres&#45;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M138.545,-447.697C133.99,-439.474 127.626,-429.483 121.225,-420.421\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.867,-418.104 115.135,-412.104 118.219,-422.24 123.867,-418.104\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/Transfer&#45;to&#45;Azure&#45;Blob -->\n",
       "<g id=\"node3\" class=\"node\"><title>mpe&#45;data&#45;pipeline/Transfer&#45;to&#45;Azure&#45;Blob</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"172.5,-340 23.5,-340 23.5,-304 172.5,-304 172.5,-340\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-318.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Transfer&#45;to&#45;Azure&#45;Blob</text>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/Postgres&#45;data&#45;&gt;mpe&#45;data&#45;pipeline/Transfer&#45;to&#45;Azure&#45;Blob -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/Postgres&#45;data&#45;&gt;mpe&#45;data&#45;pipeline/Transfer&#45;to&#45;Azure&#45;Blob</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M92.0843,-375.697C91.2886,-367.983 91.0621,-358.712 91.4047,-350.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"94.8984,-350.324 92.105,-340.104 87.9154,-349.836 94.8984,-350.324\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/Postgres&#45;data&#45;&gt;mpe&#45;data&#45;pipeline/Transfer&#45;to&#45;Azure&#45;Blob -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/Postgres&#45;data&#45;&gt;mpe&#45;data&#45;pipeline/Transfer&#45;to&#45;Azure&#45;Blob</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.916,-375.697C104.711,-367.983 104.938,-358.712 104.595,-350.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.085,-349.836 103.895,-340.104 101.102,-350.324 108.085,-349.836\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/Azure Data Factory&#45;Job -->\n",
       "<g id=\"node4\" class=\"node\"><title>mpe&#45;data&#45;pipeline/Azure Data Factory&#45;Job</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"173.5,-268 22.5,-268 22.5,-232 173.5,-232 173.5,-268\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-246.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Azure Data Factory&#45;Job</text>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/Transfer&#45;to&#45;Azure&#45;Blob&#45;&gt;mpe&#45;data&#45;pipeline/Azure Data Factory&#45;Job -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/Transfer&#45;to&#45;Azure&#45;Blob&#45;&gt;mpe&#45;data&#45;pipeline/Azure Data Factory&#45;Job</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M92.0843,-303.697C91.2886,-295.983 91.0621,-286.712 91.4047,-278.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"94.8984,-278.324 92.105,-268.104 87.9154,-277.836 94.8984,-278.324\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/Transfer&#45;to&#45;Azure&#45;Blob&#45;&gt;mpe&#45;data&#45;pipeline/Azure Data Factory&#45;Job -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/Transfer&#45;to&#45;Azure&#45;Blob&#45;&gt;mpe&#45;data&#45;pipeline/Azure Data Factory&#45;Job</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.916,-303.697C104.711,-295.983 104.938,-286.712 104.595,-278.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.085,-277.836 103.895,-268.104 101.102,-278.324 108.085,-277.836\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/Azure&#45;Blob&#45;to&#45;AWS&#45;S3 -->\n",
       "<g id=\"node5\" class=\"node\"><title>mpe&#45;data&#45;pipeline/Azure&#45;Blob&#45;to&#45;AWS&#45;S3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"174,-196 22,-196 22,-160 174,-160 174,-196\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-174.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Azure&#45;Blob&#45;to&#45;AWS&#45;S3</text>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/Azure Data Factory&#45;Job&#45;&gt;mpe&#45;data&#45;pipeline/Azure&#45;Blob&#45;to&#45;AWS&#45;S3 -->\n",
       "<g id=\"edge7\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/Azure Data Factory&#45;Job&#45;&gt;mpe&#45;data&#45;pipeline/Azure&#45;Blob&#45;to&#45;AWS&#45;S3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M92.0843,-231.697C91.2886,-223.983 91.0621,-214.712 91.4047,-206.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"94.8984,-206.324 92.105,-196.104 87.9154,-205.836 94.8984,-206.324\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/Azure Data Factory&#45;Job&#45;&gt;mpe&#45;data&#45;pipeline/Azure&#45;Blob&#45;to&#45;AWS&#45;S3 -->\n",
       "<g id=\"edge8\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/Azure Data Factory&#45;Job&#45;&gt;mpe&#45;data&#45;pipeline/Azure&#45;Blob&#45;to&#45;AWS&#45;S3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.916,-231.697C104.711,-223.983 104.938,-214.712 104.595,-206.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.085,-205.836 103.895,-196.104 101.102,-206.324 108.085,-205.836\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/AWS&#45;lambda -->\n",
       "<g id=\"node6\" class=\"node\"><title>mpe&#45;data&#45;pipeline/AWS&#45;lambda</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"144.5,-124 51.5,-124 51.5,-88 144.5,-88 144.5,-124\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-102.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">AWS&#45;lambda</text>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/Azure&#45;Blob&#45;to&#45;AWS&#45;S3&#45;&gt;mpe&#45;data&#45;pipeline/AWS&#45;lambda -->\n",
       "<g id=\"edge9\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/Azure&#45;Blob&#45;to&#45;AWS&#45;S3&#45;&gt;mpe&#45;data&#45;pipeline/AWS&#45;lambda</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M92.0843,-159.697C91.2886,-151.983 91.0621,-142.712 91.4047,-134.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"94.8984,-134.324 92.105,-124.104 87.9154,-133.836 94.8984,-134.324\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/Azure&#45;Blob&#45;to&#45;AWS&#45;S3&#45;&gt;mpe&#45;data&#45;pipeline/AWS&#45;lambda -->\n",
       "<g id=\"edge10\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/Azure&#45;Blob&#45;to&#45;AWS&#45;S3&#45;&gt;mpe&#45;data&#45;pipeline/AWS&#45;lambda</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.916,-159.697C104.711,-151.983 104.938,-142.712 104.595,-134.112\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.085,-133.836 103.895,-124.104 101.102,-134.324 108.085,-133.836\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/mpe&#45;data&#45;pipeline&#45;SLA -->\n",
       "<g id=\"node7\" class=\"node\"><title>mpe&#45;data&#45;pipeline/mpe&#45;data&#45;pipeline&#45;SLA</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"171,-52 25,-52 25,-16 171,-16 171,-52\"/>\n",
       "<text text-anchor=\"middle\" x=\"98\" y=\"-30.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">mpe&#45;data&#45;pipeline&#45;SLA</text>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/AWS&#45;lambda&#45;&gt;mpe&#45;data&#45;pipeline/mpe&#45;data&#45;pipeline&#45;SLA -->\n",
       "<g id=\"edge11\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/AWS&#45;lambda&#45;&gt;mpe&#45;data&#45;pipeline/mpe&#45;data&#45;pipeline&#45;SLA</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M92.0843,-87.6966C91.2886,-79.9827 91.0621,-70.7125 91.4047,-62.1124\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"94.8984,-62.3243 92.105,-52.1043 87.9154,-61.8356 94.8984,-62.3243\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/AWS&#45;lambda&#45;&gt;mpe&#45;data&#45;pipeline/mpe&#45;data&#45;pipeline&#45;SLA -->\n",
       "<g id=\"edge12\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/AWS&#45;lambda&#45;&gt;mpe&#45;data&#45;pipeline/mpe&#45;data&#45;pipeline&#45;SLA</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M103.916,-87.6966C104.711,-79.9827 104.938,-70.7125 104.595,-62.1124\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"108.085,-61.8356 103.895,-52.1043 101.102,-62.3243 108.085,-61.8356\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/OS&#45;linux2 -->\n",
       "<g id=\"node8\" class=\"node\"><title>mpe&#45;data&#45;pipeline/OS&#45;linux2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"89.5,-484 16.5,-484 16.5,-448 89.5,-448 89.5,-484\"/>\n",
       "<text text-anchor=\"middle\" x=\"53\" y=\"-462.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">OS&#45;linux2</text>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/OS&#45;linux2&#45;&gt;mpe&#45;data&#45;pipeline/Postgres&#45;data -->\n",
       "<g id=\"edge13\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/OS&#45;linux2&#45;&gt;mpe&#45;data&#45;pipeline/Postgres&#45;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M58.2079,-447.697C62.6456,-439.474 68.8669,-429.483 75.138,-420.421\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.1199,-422.269 81.1093,-412.104 72.4338,-418.186 78.1199,-422.269\"/>\n",
       "</g>\n",
       "<!-- mpe&#45;data&#45;pipeline/OS&#45;linux2&#45;&gt;mpe&#45;data&#45;pipeline/Postgres&#45;data -->\n",
       "<g id=\"edge14\" class=\"edge\"><title>mpe&#45;data&#45;pipeline/OS&#45;linux2&#45;&gt;mpe&#45;data&#45;pipeline/Postgres&#45;data</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M70.0393,-447.697C76.0469,-439.644 82.5246,-429.894 87.8438,-420.982\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"90.9924,-422.526 92.8994,-412.104 84.9095,-419.062 90.9924,-422.526\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1f0c2bc1a00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dependencies\n",
    "workflow.chain(\n",
    "    [myJobOS1, myJobDB1,myJobAZ1,myJobADF,myJobBlobS3,myJobAWS,jobSLA],inpath=Myfolder\n",
    ")\n",
    "workflow.chain(\n",
    "    [myJobOS2,myJobDB1],inpath=Myfolder\n",
    ")\n",
    "\n",
    "if workflow.build().is_ok():\n",
    "    print('The workflow is valid!')\n",
    "\n",
    "else:\n",
    "    print('The workflow is NOT valid!')\n",
    "    print(workflow.build().errors)\n",
    "\n",
    "#workflow.dumps_json(indent=4)\n",
    "get_graph(workflow)\n",
    "#graph = get_graph(workflow)\n",
    "#graph.render(\"test_graph\", format='png')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight: 400; font-size: 16px; font-style: normal\">4. Deploy to Check-in</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The workflow was deployed to Control-M!\n"
     ]
    }
   ],
   "source": [
    "if workflow.deploy().is_ok():\n",
    "    print('The workflow was deployed to Control-M!')\n",
    "else:\n",
    "    print('The workflow is NOT deployed!')\n",
    "    print(workflow.deploy().errors)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight: 400; font-size: 16px; font-style: normal\">5. Run</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run\n",
      "Run Status\n",
      "--------------------------------------------------\n",
      "    mpe-data-pipeline  .................  Executing\n",
      "    OS-linux1  .........................  Ended OK\n",
      "    Postgres-data  .....................  Wait Condition\n",
      "    Transfer-to-Azure-Blob  ............  Wait Condition\n",
      "    Azure Data Factory-Job  ............  Wait Condition\n",
      "    Azure-Blob-to-AWS-S3  ..............  Wait Condition\n",
      "    AWS-lambda  ........................  Wait Condition\n",
      "    mpe-data-pipeline-SLA  .............  Wait Condition\n",
      "    OS-linux2  .........................  Executing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Run')\n",
    "run = workflow.run()\n",
    "run.print_statuses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:green;font-weight: 400; font-size: 16px; font-style: normal\">6. Monitor, Display output, Rerun, Set to OK ...</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Status\n",
      "--------------------------------------------------\n",
      "    mpe-data-pipeline  .................  Executing\n",
      "    OS-linux1  .........................  Ended OK\n",
      "    Postgres-data  .....................  Ended OK\n",
      "    Transfer-to-Azure-Blob  ............  Ended Not OK\n",
      "    Azure Data Factory-Job  ............  Wait Condition\n",
      "    Azure-Blob-to-AWS-S3  ..............  Wait Condition\n",
      "    AWS-lambda  ........................  Wait Condition\n",
      "    mpe-data-pipeline-SLA  .............  Wait Condition\n",
      "    OS-linux2  .........................  Ended OK\n",
      "\n",
      "+ Job started at '0229 08:30:36:524' orderno - '06qol' runno - '00001' Number of transfers - 1, Job name - 'Transfer-to-Azure-Blob'\n",
      "+ Host1 'zzz-eks-sandbox-1.bmci2t.com' [Unix-SFTP] username 'bmc' - Host2 ['AZURE' - Connection Profile: 'ZZZ_MFT_BLOB', Container:\\\n",
      " 'incoming']\n",
      "Local host is zzz-eks-sandbox-1.bmci2t.com\n",
      "Connection Profile 'ZZZ_MFT_FS_1' is stored in EM database.\n",
      "Connection Profile 'ZZZ_MFT_BLOB' is stored in EM database.\n",
      "+********** Starting transfer #1 out of 1**********\n",
      "Transfer #1 start time: 08:30:36\n",
      "Connection to SFTP server on host zzz-eks-sandbox-1.bmci2t.com was established\n",
      "Connection to AZURE server on host Azure was established\n",
      "File '/tmp/snowflake_query.csv' not found on host 'zzz-eks-sandbox-1.bmci2t.com', no such file or directory\n",
      "Failed to retrieve file size. Source file '/tmp/snowflake_query.csv' doesn't exist\n",
      "The job failed before the transfer completed\n",
      "Failed in job Transfer-to-Azure-Blob in file transfer #1\n",
      "\n",
      "Job ended at '0229 08:30:38:548'\n",
      "Elapsed time [2 sec]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run.print_statuses()\n",
    "run.print_output('mpe-data-pipeline/Transfer-to-Azure-Blob')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e2ab4699a82da9ada95853d3c0abb8d0fd7cf10101d98483eced78fe436a9538"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
